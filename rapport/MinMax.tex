%!TEX root=main.tex

\subsubsection{Jeux Min-Max avec coût}

% DEFINITION: jeu Min-Max avec coût

\begin{defi}[Jeu Min-Max avec coût] $\text{ }$\\
	Soit une arène $\mathcal{A} = (V, (V_{Min}, V_{Max}), E) $
	Un \textit{jeu Min-Max avec coût} est un tuple $\mathcal{G} = (\mathcal{A}, Cost_{Min}, Gain_{Max})$, où
	\begin{enumerate}
		\item[$\bullet$] $Cost_{Min}: Plays \rightarrow \mathbb{R} \cup \{+ \infty, -\infty \}$ est la \textit{fonction de coût} du joueur \textit{Min}.
		\item[$\bullet$] $Gain_{Max}: Plays \rightarrow \mathbb{R} \cup \{ + \infty, -\infty \}$ est la \textit{fonction de gain} du joueur \textit{Max}.
	\end{enumerate}
		
\end{defi}

\begin{rem}
	Dans cette définition, on sous-entend que $\Pi = \{ Min, Max \}$.
\end{rem}

Pour chaque $\rho \in Plays$, $Cost_{Min}(\rho)$ représente le montant que \textit{Min} perd quand le jeu $\rho$ est joué et $Gain_{Max}(\rho)$ représente le gain que \textit{Max} gagne quand le jeu $\rho$ est joué.
Le but de \textit{Min} (resp. \textit{Max}) est donc de \textbf{minimiser} (resp. \textbf{maximiser}) sa fonction de coût (resp. fonction de gain). Ce qui explique le choix des noms des joueurs.\\

%DEFINITION: jeu Min-Max à somme nulle

\begin{defi}[Jeu à somme nulle]
	Un jeu Min-Max avec coût est dit \textit{à somme nulle} si $Gain_{Max} = Cost_{Min}$.
\end{defi}

% DEFINITION: garantir le paiement

\begin{defi}[Garantir le paiement]$\text{}$\\
	
	Soit $(\mathcal{G}, v_{0})$ un jeu Min-Max avec coût initialisé,
	
	\begin{center}On dit que le joueur \textit{Max} \textit{garantit le paiement} $d \in \mathbb{R}$ dans $(\mathcal{G}, v_{0})$\\ 
		ssi \\ 
	$\exists \sigma _{1} \in \Sigma _{Max}$ tq $\forall \sigma _{2} \in \Sigma _{Min}$ $ Gain_{Max}(\rho) \geq d$\\
	où $ \rho = \langle \sigma _{1},\sigma _{2} \rangle_{v_0}$\end{center}
	
	\begin{center} 
		On dit que le joueur \textit{Min} \textit{garantit le paiement} $d \in \mathbb{R}$ dans $(\mathcal{G}, v_{0})$\\		
		ssi	\\
		$\exists \sigma _{1}\in \Sigma _{Min}$ tq $\forall \sigma _{2} \in \Sigma _{Max}$ $ Cost_{Min}(\rho) \leq d$ \\
		où $ \rho = \langle \sigma _{1},\sigma _{2}\rangle_{v_0}$
		\end{center}

\end{defi}
		

% DEFINITION: Valeur supérieure et valeur inférieure

\begin{defi}[Valeur inférieure/supérieure]
	
	Soit $\mathcal{G}$ un jeu Min-Max avec coût, on définit pour chaque sommet $v \in V$: 
	\begin{enumerate}
		\item[$\bullet$]\textit{Valeur supérieure:} $\overline{Val}(v) = \inf\limits_{\sigma _{1} \in \Sigma _{Min}} \sup\limits_{\sigma _{2} \in \Sigma_{Max}} Cost_{Min}(\rho)$ où $\rho = \langle \sigma _{1},\sigma _{2}\rangle_v$
		
		\item[$\bullet$]\textit{Valeur inférieure:} $\underline{Val}(v) = \sup\limits_{\sigma _{2} \in \Sigma_{Max}}  \inf\limits_{\sigma _{1} \in \Sigma _{Min}} Gain_{Max}(\rho)$  où $\rho = \langle \sigma _{1},\sigma _{2}\rangle_v$
	\end{enumerate}
\end{defi}
\begin{rem}
	La \textit{valeur supérieure}  $\overline{Val}(v)$ est la plus petite valeur dont $J_{Min}$ garantit le paiement dans $(\mathcal{G},v)$ et la \textit{valeur inférieure} $\underline{Val}(v) $ est la plus grande valeur dont $J_{Max}$ garantit le paiement dans $(\mathcal{G},v)$.
\end{rem}

%PROPRIETE 
\begin{propriete}
	Pour tout $v \in V$, on a : $\underline{Val}(v) \leq \overline{Val}(v)$
\end{propriete}

%DEFINITION: jeu déterminé et valeur d'un jeu

\begin{defi}[Jeu déterminé et valeur d'un jeu]
		Soit $\mathcal{G}$ un jeu Min-Max avec coût, on dit que $\mathcal{G}$ est \textit{déterminé} si pour tout $v \in V$, $\overline{Val}(v) = \underline{Val}(v)$. On dit alors que le jeu $\mathcal{G}$ a une \textit{valeur} et pour tout $v \in V$ on note $Val(v) = \overline{Val}(v) = \underline{Val}(v)$.
\end{defi}

%DEFINITION: Stratégie optimale

\begin{defi}[Stratégie $\varepsilon$-optimale]
	Soit $\epsilon > 0$,
	\begin{enumerate}
	\item[$\bullet$] $\sigma _{2} \in \Sigma _{Max}$ est une \textit{stratégie $\varepsilon$-optimale} ssi $\forall v \in V $ $ \forall \sigma _{1}\in \Sigma_{Min}$ $ Gain_{Max}(\rho) \geq \underline{Val}(v) - \varepsilon  $\\ où $\rho = \langle \sigma _{1},\sigma _{2} \rangle_v$.
	\item[$\bullet$] $\sigma _{1} \in \Sigma _{Min}$ est une \textit{stratégie $\varepsilon$-optimale} ssi $\forall v \in V $ $ \forall \sigma _{2}\in \Sigma_{Max}$ $Cost_{Min}(\rho) \leq \overline{Val}(v) + \varepsilon $\\ où $\rho = \langle \sigma _{1},\sigma _{2} \rangle_v$.
	\item[$\bullet$] Si $\varepsilon = 0$, on dit que la stratégie $\sigma _{i}$ est \textit{optimale}
	\end{enumerate}
\end{defi}

%DEFINITION: reachability-price game

\begin{defi}[Reachability-price game]
	Soit $\mathcal{A} = (V, (V_{Min}, V_{Max}), E) $,soit $w: E \rightarrow \mathbb{R}$ une fonction de poids,
	un \textit{"reachability-price game"} est un jeu Min-Max avec coût $\mathcal{G} = (\mathcal{A},RP_{Min},RP_{Max})$\\ avec un objectif donné $Goal \subseteq V$, où pour tout $\rho \in Plays$ tq $\rho = \rho _{0}\rho _{1}...$:\\
	
	$g := RP_{Min}(\rho)=RP_{Max}(\rho) =$ $\begin{cases}
									\sum_{i = 0}^{n-1} w(\rho_{i},\rho_{i+1}) & \text{ si } n \text{ est le plus petit indice tq } \rho_{n}\in 					  Goal\\
									+\infty & \text{sinon}
									\end{cases}$ \\
									
  \noindent Ce jeu est un jeu à somme nulle et nous le notons : $\mathcal{G} = (\mathcal{A}, g , Goal)$.
\end{defi}

% EXEMPLE : reachability-price game + jeu déterminé + valeur + stratégie optimale

\input{reachPriceGame1}

Dans~\cite{DBLP:conf/lfcs/BrihayePS13} le théorème suivant est énoncé:

\begin{thm}
	\label{thm:1}
	Les \og\textit{reachability-price games}\fg~ tels que la fonction de poids associée au graphe est positive sont déterminés et ont des stratégies optimales sans mémoire.
\end{thm}


Au vu du résultat ~\ref{thm:1} précédent, comme dans le cas des jeux d'atteignabilité à objectif qualitatif nous nous interrogeons quant à la façon d'implémenter un algorithme pour résoudre les \og \textit{reachability-price games} \fg. L'objectif de cet algorithme est de trouver une stratégie optimale pour chaque joueur ainsi que la valeur associée à chaque sommet du graphe. L'idée est la suivante: le joueur \textit{Min} a pour but d'emprunter un \textbf{plus court chemin} possible allant d'un noeud initial $v_{0}$ vers un noeud $v \in Goal$. On trouve dans la littérature différents algorithmes qui résolvent les problèmes de plus court chemin dans les graphes orientés. Toutefois, il n'y a pas de deuxième joueur qui agit de manière \textbf{antagoniste} face au joueur \textit{Min} qui entre en compte dans ces algorithmes. C'est pourquoi, nous avons tenté une adaptation de l'algorithme de \textit{Dijkstra} (que nous rappelons dans l'annexe A (p.\pageref{algo:dijkstra})). Après avoir pris connaissance du travail de Simon Olbregts~\ref{simon} une comparaison et une refactorisation de notre algorithme basées sur le pseudo-code qu'il a lui-même proposé ont été effectuées.

De manière similaire à l'algorithme de Dijkstra, la fonction de coût associée au graphe doit être de la forme $w : E \rightarrow \mathbb{R}^{+}_{0}$. Le fait que la valeur 0 soit exclue des valeurs possibles pour les poids des arcs est expliqué dans la preuve d'exactitude de l'algorithme. Le but de l'algorithme est de calculer le paiement minimum que le joueur \textit{Min} peut garantir quelle que soit la stratégie adoptée par le joueur \textit{Max}. Du fait que le joueur \textit{Max} joue de manière antagoniste par rapport au joueur \textit{Min}, à chaque fois que c'est au joueur \textit{Max} de prendre une décision il voudra maximiser son gain. Pour ce faire, on aura besoin de connaître le chemin le plus coûteux allant du sommet du joueur \textit{Max} en cours de traitement vers un certain état objectif $o \in Goal$. Dès lors, contrairement à l'algorithme classique de Dijkstra qui part d'une source, l'algorithme s'exécutera à rebours à partir des états $o \in Goal$. Ci-dessous nous reprenons les idées essentielles de l'algorithme proposé ainsi que son pseudo-code.\\

\noindent \textbf{Idées de l'algorithme}\\

\begin{enumerate}
	
	\item[$\bullet$] A tout sommet $v \in V$ on associe une valeur $d$ qui représente l'estimation de la valeur $Val(v)$ (qui existe par le théorème ~\ref{thm:1}). Cette valeur est mise à jour en cours d'exécution de l'algorithme de sorte qu'à la fin de celle-ci on ait pour tout $v \in V$ $Val(v) = d$. Comme pour l'algorithme de Dijkstra, on initialise la valeur des sommets à $+\infty$ sauf pour les sommets objectifs $o \in Goal$ pour lesquels on initialise la valeur à 0.
	
	\item[$\bullet$] De plus, pour tout sommet $v \in V$, on associe un \textit{tas} $S$  qui est mis à jour en cours d'exécution. En effet, si $v \in V_{Max}$, à chaque fois qu'un des successeurs $s$ de $v$ est relaxé (\emph{i.e.,} dont on a fini le traitement) on ajoute un couple $(val,s)$ au tas. La valeur $val$ est calculée de la manière suivante : $val = w(v,s) + s.d$. La preuve d'exactitude montre qu'en fait, $s.d = Val(s)$ car le noeud $s$ a été complètement traité lorsque l'on rajoute $(val,s)$ dans le tas correspondant au noeud $v$. Dans le cas où $v \in V_{Min}$ seule la valeur $val$ minimale donnée par le calcul explicité précédemment est importante. On ne garde donc pas trace de toutes les valeurs calculées à chaque fois qu'un successeur est relaxée mais uniquement de la minimale.
	
	\item[$\bullet$] Pour tout sommet $v \in V_{Max}$, on associe le nombre de successeurs que ce sommet possède. On note ce nombre : $nbrSucc$. De plus, si l'on désire reconstituer la stratégie optimale pour le joueur \textit{Max}, on stocke dans une structure de données adéquate la liste des successeurs déjà testés pour la recherche du chemin le plus long.
	
		\item[$\bullet$] On utilise un \textit{tas} $Q$ qui permet de stocker les sommets classés par leur valeur $d$. Sur cetas, on peut effectuer les opérations suivantes: insertion d'un élément, extraction d'un élément ayant la clef de la plus petite valeur, lecture de l'élément ayant la clef de la plus petite valeur, test de la présence ou non d'élément dans $Q$, augmentation ou diminution de la valeur de la clef associée à un sommet. A l'initialisation de l'algorithme les sommets présents dans $Q$ sont tous ceux présents dans $V$.
	
	\item[$\bullet$] On maintient $T \subseteq V$ un ensemble de sommets qui vérifient la propriété suivante: pour tout sommet $v \in V$ $Val(v) = d$. Il s'agit donc de l'ensemble des sommets dont le traitement est terminé. A l'initialisation de l'algorithme $T = \emptyset$.
	
	\item[$\bullet$] Tant que $Q \neq \emptyset$, l'algorithme procède de la manière suivante: 
	\begin{enumerate}
		\item On regarde la valeur du minimum de $Q$ et le sommet $s$ associé.
		\item Si cette valeur est $+\infty$, alors cela signifie qu'on a fini de traiter tous les sommets qui pouvaient atteindre un sommet objectif. On ajoute donc tous les sommets restants de $Q$ dans $T$.
		\item S'il s'agit d'un sommet du joueur \textit{Min} ou d'un sommet objectif $o$ alors on extrait le minimum de $Q$ et on l'ajoute à $T$, on \textit{relaxe} tous les arcs entrant de $s$. Il est va de même si le sommet est un sommet de joueur \textit{Max} et que la valeur de $nbrSucc$ est égale à 1. En effet, cela signifie qu'il n'a pas le choix du chemin à emprunter.
		\item S'il s'agit d'un sommet du joueur \textit{Max} tel que la valeur de $nbrSucc$ n'est pas égale à 1 alors, alors \textit{Max} a plusieurs choix de chemin. Pour maximiser son gain, il ne choisira pas de passer par le successeur $s$ tel que la valeur de $w(v,s) + Val(s)$ est la plus petite. On retire donc la plus petite valeur de $S$, on met à jour la clef de $s$ dans $Q$ et on décrémente $nbrSucc$. Un tel arc $(v,s)$ est alors considéré comme \og bloqué \fg. Ainsi, on sait qu'il y a un successeur de moins à traiter et on ajoute ce successeur à l'ensemble des successeurs déjà traités. En effet, on désire que la dernière valeur restante dans $s.Q$ soit celle qui assure la maximisation du gain de \textit{Max}.
	\end{enumerate}
	
	\item[$\bullet$] La \textit{relaxation} des arcs entrants de $s$ consiste en la méthode suivante: pour tout $(p,s)\in E$ on lit le minimum de $s.S$ (qui est en fait $Val(s)$), on calcule la nouvelle estimation de la valeur du sommet $p$. Si $p \in V_{Max}$ on insère cette valeur associée à $s$ dans $p.S$. De plus dans tous les cas, si cette nouvelle valeur est plus petite que $p.d$ on met à jour $p.d$ dans $Q$ et si $p \in V_{Min}$ on met à jour la valeur de la racine du tas $p.S$. 
	
\end{enumerate}

\noindent \textbf{Pseudo-code}\\

Soient $\mathcal{A} = (V, (V_{Min}, V_{Max}), E) $ une arène et $\mathcal{G} = (\mathcal{A}, g, Goal)$ un \og \textit{reachability-prince game} \fg. Nous utilisons les notations suivantes : 
\begin{enumerate} 
	\item[$\bullet$]$Q$ et $S$ sont les tas décrits ci-dessus.
	\item[$\bullet$]$s.S$  correspond au tas $S$ du sommet $s$.
	\item[$\bullet$]$T$ est le sous-ensemble de $V$ décrit ci-dessus.
	\item[$\bullet$]Pour tout $v \in V$, $Pred(v)$ (resp. $Succ(v)$) est l'ensemble des prédécesseurs (resp. successeurs) de $v$.
	\item[$\bullet$]Pour tout $v \in V$, $v.d$ est l'estimation de $Val(v)$.
	\item[$\bullet$]Pour tout $v \in V_{Max}$, $v.nbrSucc$ est le nombre de successeurs de $v$ qu'il reste à tester, $v.t$ est l'ensemble des successeurs de $v$ déjà testés.
\end{enumerate}

L'algorithme en lui même est explicité par l'algorithme ~\ref{algo:dijkMinMax} et les algorithmes \ref{algo:initS},\ref{algo:initQ},\ref{algo:relaxerMinMax},\ref{algo:bloquerMax} sont appelés au sein de l'algorithme ~\ref{algo:dijkMinMax}.
Comme pour l'algorithme de Dijkstra, pour une meilleure complexité les files de priorité sont supposées implémentées par une structure de données telle que chaque opération \textsc{Extraire-Min}() ainsi que chaque insertion et suppression d'un élément sont en $\mathcal{O}(\log_2 V)$ ainsi que chaque \textsc{DécrémenterClef}($Clef(v),nouvVal$). De plus, \textsc{Lire-Min()} doit être implémenté en $\mathcal{O}(1)$. Ici nous avons choisi d'utiliser des tas. \\ 

%ALGO: DijkstraMinMax

\begin{algorithm}
	\caption{\textsc {DijkstraMinMax}(G,w,Goal)}
	 \label{algo:dijkMinMax}
	\begin{algorithmic}[1]
		\REQUIRE $G = (V,E)$ un graphe orienté pondéré où $E$ est représenté la liste des prédécesseurs de chaque noeud, $w: E \rightarrow \mathbb{R}^{+}$ une fonction de poids, $Goal$ l'ensemble des sommets objectifs.
		\ENSURE / \textbf{\textsc{Effet(s) de bord :}} Calcule pour chaque noeud la valeur de ce noeud.
		
		\STATE $Q \leftarrow$\textsc{Initialiser-Q}($G,Goal$)
		\STATE $S \leftarrow$\textsc{Initialiser-S}($G,Goal$)
		
		\STATE $T \leftarrow \emptyset$
		\WHILE {$Q \neq \emptyset$} \label{lalgo:dijk4}
			\STATE $s \leftarrow Q.\textsc{Lire-Min()}$ \label{lalgo:dijk1}
			\STATE $(val,succ) \leftarrow s.S.$\textsc{Lire-Min}$()$ \label{lalgo:dijk6}
			\IF{$val = +\infty$} \label{lalgo:dijk7}
					\STATE $u \leftarrow Q.$\textsc{Extraire-Min}$()$
					\STATE $T.$\textsc{Insérer}$(u)$ \label{lalgo:dijk11}
			\ELSE \label{lalgo:dijk12}
				\IF{($s \in V_{Min} \cup \{ Goal \}$) ou ($s.nbrSucc = 1$)} \label{lalgo:dijk13}
					\STATE $s \leftarrow Q.$\textsc{Extraire-Min}$()$
					\STATE $T.$\textsc{Insérer}$(s)$
					\FORALL{$p \in Pred(s)$}
						\STATE \textsc{Relaxer}$(p,s,w)$ \label{lalgo:dijk2}
					\ENDFOR \label{lalgo:dijk18}
				
				
				\ELSE \label{lalgo:dijk19}
					\STATE \textsc{Bloquer-Max}$(s)$
				\ENDIF \label{lalgo:dijk21}
			\ENDIF\label{lalgo:dijk22}
		\ENDWHILE \label{lalgo:dijk23}
				
			
\end{algorithmic}
		
\end{algorithm}

%ALGO: Initialiser-S

\begin{algorithm}
	\caption{\textsc {Initialiser-S}($G,Goal)$}
	 \label{algo:initS}
	\begin{algorithmic}[1]
		\REQUIRE $G$ un graphe orienté pondéré et l'ensemble des objectifs $Goal$.
		\ENSURE / \textbf{\textsc{Effet(s) de bord :}} initialise les files de priorité de tous les sommets.
		
		\FORALL{$o \in Goal$}
			\STATE $S \leftarrow$ nouveau tas
			\STATE $o.S \leftarrow S$
			\STATE $o.S.$\textsc{Insérer}$(0, NULL)$
		\ENDFOR
		
		\FORALL{$v \in G.V\backslash \{ Goal \}$}
			\STATE $S \leftarrow$ nouveau tas
			\STATE $v.S \leftarrow S$
			\STATE $v.S.$\textsc{Insérer}$(+\infty, NULL)$
		\ENDFOR
		
	
			
\end{algorithmic}
		
\end{algorithm}

%ALGO: Initialiser-Q


\begin{algorithm}
	\caption{\textsc {Initialiser-Q}$(G,Goal)$}
	 \label{algo:initQ}
	\begin{algorithmic}[1]
		\REQUIRE $G$ un graphe orienté pondéré, l'ensemble des états objectifs $Goal$.
		\ENSURE Un tas $Q$ qui comprend tous les sommets de $V$ classés par leur valeur $d$.
		
		\STATE $Q \leftarrow$ nouveau tas 
		\FORALL{$v \in G.V \backslash \{ Goal \}$}
			\STATE $v.d \leftarrow +\infty$
			\STATE $Q.$\textsc{Insérer}(v)
		\ENDFOR
		\FORALL{$o \in Goal$}
			\STATE $o.d \leftarrow 0$
			\STATE $Q.$\textsc{Insérer}(o)	
		\ENDFOR
		
		\RETURN $Q$
	
			
\end{algorithmic}
		
\end{algorithm}

%ALGO:Relaxer

\begin{algorithm}
	\caption{\textsc {Relaxer}$(p,s,w)$}
	 \label{algo:relaxerMinMax}
	\begin{algorithmic}[1]
		\REQUIRE deux sommets $p$ et $s$, une fonction de poids $w : E \rightarrow \mathbb{R}^{+}_{0}$.
		\ENSURE / \textbf{\textsc{Effet(s) de bord :}} Ajoute à p.S une valeur pour $p$ et son successeur dans le cas où
		$p$ est un noeud du jouer $\textit{Max}$ et met à jour la valeur de la racine sinon.
		
		\STATE $(sVal,succ)$ $\leftarrow$ \textsc{Lire-Min(s.S)} \label{lalgo:relaxer1}
		\STATE $pVal \leftarrow w(p,s) + sVal$	
		\STATE $old \leftarrow p.S.$\textsc{Lire-Min()} 
		\STATE $p.S.$\textsc{Insérer}$((pVal,s))$ \label{lalgo:relaxer4}
		\IF{$pVal < old$} \label{lalgo:relaxer5}
			\STATE $Q.$\textsc{Décrémenter-Clef}$(p,pVal)$ 
			\IF{$p \in V_{Min}$} 
				\STATE $p.S[0] \leftarrow pVal$
			\ENDIF 
		\ENDIF \label{lalgo:relaxer10}
		
		\IF{$p \in V_{Max}$} \label{lalgo:relaxer11}
			\STATE $p.S.$\textsc{Insérer}$((pVal,s))$ 
		\ENDIF \label{lalgo:relaxer12}
			
\end{algorithmic}
		
\end{algorithm}

%ALGO:Traiter-Max

\begin{algorithm}
	\caption{\textsc {Bloquer-Max}$(s)$}
	 \label{algo:bloquerMax}
	\begin{algorithmic}[1]
		\REQUIRE un sommet $s$ appartenant au joueur \textit{Max} tel que $s.nbrSucc \neq 1$.
		\ENSURE / \textbf{\textsc{Effet(s) de bord :}} traite le sommet $s$ en supprimant la plus petite valeur de s.S et met
		à jour la liste $t$ de successeurs de $s$ déjà testés.
		
			\STATE $(val,succ) \leftarrow$ $s.S.$\textsc{Extraire-Min}() \label{lalgo:bloc1}
			\STATE $(nouvVal,nouvSucc) \leftarrow$ $s.S.$\textsc{Lire-Min}()
			\STATE $Q.$\textsc{Incrémenter-Clef}$(s,nouvVal)$ \label{lalgo:bloc2}
			\STATE $s.nbrSucc \leftarrow s.nbrSucc - 1 $
			\STATE $s.t.$\textsc{Insérer}$(succ)$
			
				
			
\end{algorithmic}
		
\end{algorithm}

\FloatBarrier




On remarque que l'algorithme \textsc{DijkstraMinMax}  est un algorithme à effet de bord mais ne renvoie aucune valeur. Pour récupérer la valeur de chaque sommet $s$, ainsi qu'une stratégie optimale pour $J_{Min}$ et une strategie optimale pour $J_{max}$, il suffit de récupérer la racine de $s.S$ qui comprend $Val(s)$ ainsi que le successeur qu'il faut emprunter pour obtenir cette valeur. On obtient alors les algorithmes \textsc{RécupérerStratégies} (qui récupère une stratégie optimale pour chaque joueur) et \textsc{RécupérerValeurs} qui récupère la valeur de chaque noeud).

\begin{rem}
	
	Dans le cas où $Val(v) = +\infty$, nous n'avons pas de successeur à notre disposition dans la file de priorité. Comme les fonctions de stratégie sont des fonctions totales, il faut toutefois définir $\sigma _{i} (v)$.
\begin{enumerate}
	\item[$1^{er} cas:$] Si $v \in V_{Min}$ alors cela signifie que pour tout $s \in V$ tq $(v,s) \in E$ on a : $Val(s) = +\infty$. En effet, s'il existe $s' \in V$ tq $(v,s')\in E$ et $Val(v') < +\infty$ alors $J_{Min}$ a tout intérêt à jouer $\sigma _{Min}(v) = s'$.
	\item[$2^{eme} cas:$] Si $v \in V_{Max}$ alors cela signifie qu'il existe $s \in V$ tq $(v,s) \in E$ tq : $Val(s) = +\infty$. Sinon, pour tout $s' \in V$ tq $(v,s') \in E$ et $Val(v') < +\infty$ alors $Val(v) \neq +\infty$. 
	
\end{enumerate}

\end{rem}

\begin{algorithm}
	\caption{\textsc{RécupérerStratégies}($G$)}
	\label{algo:recupStrat}
	\begin{algorithmic}[1]
	
	\STATE \textsc{Afficher("Stratégie optimale pour $J_{Max}$")}
	\FORALL{$v \in V_{Max}$} 
		\IF{$Val(v) = +\infty$}
			\STATE Choisir $s \in Succ(v) \backslash v.t$
			\STATE \textsc{Afficher( $v$" $\rightarrow $ " $s$)}
		\ELSE
			\STATE $(val,succ) \leftarrow v.S.$\textsc{Lire-Min}$()$
			\STATE \textsc{Afficher( $v$" $\rightarrow$ " $succ$)}
		\ENDIF
	\ENDFOR
	
	\STATE \textsc{Afficher("Stratégie optimale pour $J_{Min}$")}
	\FORALL{$v \in V_{Min}$} 
		\IF{$Val(v) = +\infty$}
			\STATE Choisir $s \in Succ(v)$
			\STATE \textsc{Afficher( $v$" $ \rightarrow$ " $s$)}
		\ELSE	
			\STATE $(val,succ) \leftarrow v.S.$\textsc{Lire-Min}$()$
			\STATE \textsc{Afficher( $v $"$ \rightarrow $" $succ$)}
		\ENDIF
	\ENDFOR
	
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{\textsc{RécupérerValeurs}($G$)}
	\label{algo:recupVal}
	\begin{algorithmic}[1]
	
	\FORALL{$v \in V$} 
		\STATE $(val,succ) \leftarrow v.S.$\textsc{Lire-Min}$()$
		\STATE \textsc{Afficher( "La valeur de" $v$ "est " $val$)}
	\ENDFOR
	
	
	\end{algorithmic}
\end{algorithm}


\FloatBarrier
	

%EXEMPLE: application de l'algorithme DijkstraMinMax sur un exemple 

\input{dijkMinMaxEx}
%PREUVE de l'EXACTITUDE de l'algorithme de DijkastraMinMax
\noindent\textbf{Exactitude de l'algorithme \textsc{DijkstraMinMax}}\\

Notre but maintenant est de montrer que l'algorithme \textsc{DijkstraMinMax} est exact. C'est-à-dire que nous voulons montrer qu'à la fin de l'exécution de cet algorithme, nous connaissant $Val(v)$ pour tout $v\in V$ ainsi qu'une stratégie optimale pour le joueur Min et pour le joueur Max.
Pour ce faire, nous nous inspirons de la preuve effectuée par Simon Olbregts dans le cadre de son projet de 1\up{er} Master en sciences informatiques~\cite{simon}. 
Pour plus de clarté et de concision nous avons besoin d'introduire quelques notations:\\

\begin{itemize}
	\item[$\bullet$] Soient $x$ et $y$ des noeuds du graphe, $x \leadsto y$ représente un chemin $x$ à $y$ qui suit des stratégies optimales pour le joueur Min et le joueur Max (\emph{i.e.,}il s'agit d'un \emph{chemin optimal})
	\item[$\bullet$] $T_{i}$ est l'ensemble des noeuds traités après la i\up{ème} itération. Un noeud est considéré comme traité quand il est enlevé de $Q$.
	\item[$\bullet$] $E_i$ est les arêtes du graphe $G$ duquel on a enlevé tous les arcs sortant d'un noeud Max et qu'on ne choisissait pas d'emprunter car il existait un meilleur choix et ce après la i\up{ème} itération. Un tel arc est appelé un \emph{arc bloqué}.
	\item[$\bullet$] $\rho_i(v) := \min _{v' \in T_i}\{ w(v,v') + Val(v') \} $ où $(v,v')$ est un arc de $G_i$.
\end{itemize}

$\text{}$\\
\noindent Nous allons donc montrer que les invariants suivant sont exacts: 

\begin{enumerate}
	\item $\forall v \in T_i$ on connait la valeur $Val(v)$ et la stratégie à adopter en $v$.
	\item $\forall v \in V \backslash \{ T_i \},$ on connait $\rho_i(v)$.
\end{enumerate}
	
\noindent \underline{\textsc{A. Avant la première itération}}\\

Nous avons : $T_i = \emptyset$ et $E_i = E$ à l'initialisation de l'algorithme. Donc pour tout $v \in V$, nous connaissons $\rho_i(v)$. En effet, si $v$ est un état objectif ($v \in Goal$) alors $\rho_i(v) = 0$ sinon, $\rho_i(v) = + \infty$.\\

\noindent \underline{\textsc{B. En cours d'exécution}}\\
\todo{ attention dans l'explication de l'algo j'ai mis $\mathbb{R}^{+}$ un poids nul est donc envisageable.}

Commençons par constater que si on considère une fonction de poids de la forme $w: E \rightarrow \mathbb{N}_{0}$ alors, au vu de l'algorithme, les premières itérations de celui-ci traitent les noeuds objectifs. Lors de l'initialisation de l'algorithme les seuls noeuds placés dans $Q$ avec un poids différent de $ + \infty$ sont ceux des noeuds objectifs qui ont un poids de 0. Comme la fonction de poids est une fonction strictement positive lors des relaxations des prédécesseurs des noeuds objectifs, les valeurs présentent dans $Q$ seront toutes strictement plus grande que 0 (sauf pour les noeuds objectifs restant). Cette argumentation nous permet donc d'affirmer que pendant les $|Goal|$ premières itérations, tous les noeuds objectifs sont traités. De ce fait, nous sommes assurés que la valeur des noeuds objectifs est bien 0 et le restera tout au long de l'algorithme.

Si toutefois nous permettons les poids nuls, au vu de l'algorithme comme il est décrit actuellement nous pourrions nous retrouver face au problème suivant: si deux noeuds objectifs se trouvent sur un même chemin du type $ \ldots o_1vo_2 \ldots$ où $o_1$ et $o_2$ sont des noeuds objectifs,$v$ un noeud du joueur $Min$, $o_1$ un noeud du joueur Max et tels que $w(v,o_2) = 0$ et $w(o_1,v) = 1$ (cette situation est représentée par la figure~\ref{fig:dijk1}). Il se pourrait alors que la valeur du noeud $o_1$ soit modifiée alors qu'elle doit rester à 0. En effet, l'algorithme peut commencer à traiter le noeud $o_2$, le relaxer et donc faire passer la valeur $v.d$ à 0. Dès lors à l'itération suivante le noeud $v$ peut être choisi par l'algorithme et donc être relaxé. De ce fait la valeur 1 est placée dans le tas $o_1.S$ et comme le noeud $o_1$ du joueur Max possède plusieurs successeurs la valeur 0 du tas sera supprimée au profit de la valeur 1. Ce comportement n'est pas le comportement que nous attendons pour l'algorithme car pour tout noeud objectif $o$, $Val(o) = 0$.
Ce problème peut être évité si lors de la relaxation d'un noeud on vérifie que le prédécesseur n'est pas un noeud objectif.
\todo{Vérifier que cette solution règle bien le problème et n'en amène pas d'autres.}

\include{fig:dijk1}

Au préalable, afin de prouver que le premier invariant est correct, nous allons établir la véracité de deux propriétés dont voici les énoncés ainsi que leur preuve.

\setcounter{equation}{0}

\begin{propriete}
	\label{prop:dijk1}
	Soit $i$ une certaine étape de l'algorithme et $v \in V\backslash \{ T_i \}$ tel que $v$ se trouve sur un chemin optimal et que le successeur de $v$ sur ce chemin, notons-le $u$, ai déjà été traité (\emph{i.e.,} $u \in T_i$) alors:
	$$ v \in V_{Min} \Rightarrow \rho_i(v) = Val(v).$$
\end{propriete}

\begin{demonstration}
$\text{}$\\
	Comme nous avons pris $v$ et $u$ sur un chemin optimal cela signifie qu'il existe $(\sigma_1^*, \sigma_2^*) \in \Sigma_{Min} \times \Sigma_{Max}$ des stratégies optimales telles que pour un certain $t \in V$ on ait : $\langle \sigma_1^*, \sigma_2^* \rangle_t = t\ldots vu\ldots$ .
Nous voulons montrer que si on connait $Val(u)$ alors on a : $Val(v) = \rho_i(v)$.
On sait, vu que $\sigma_1^*$ $ \sigma_2^*$ sont des stratégies optimales, que:

\begin{align*}
Val(v) &= g(\langle \sigma_1^*,\sigma_2^* \rangle_v) \notag \\
 	   &= w(v,u) + g(\langle \sigma_1^*,\sigma_2^* \rangle_u) \notag \\
       &= w(v,u) + Val(u) 
\end{align*}

Nous voulons donc établir que:

$$ w(v,u) + Val(u) = \min_{v' \in T_i, (v,v') \in E_i} \{ w(v,v') + Val(v') \} = \min_{v' \in T_i, (v,v') \in E} \{ w(v,v') + Val(v') \}$$

La deuxième égalité est due au fait qu'on ne bloque pas d'arc issu d'un noeud du joueur Min et que $v\in V_{Min}$.
De plus, comme le noeud $u$ a déjà été entièrement traité, on connait $Val(u)$ et il a été relaxé. De ce fait, la valeur $w(v,u) + Val(u)$ se trouve dans $v.S$ et calculer $\min_{v' \in T_i, (v,v') \in E} \{ w(v,v') + Val(v') \}$ revient à prendre le minimum du tas $v.S$.

Par l'absurde, supposons que $ w(v,u) + Val(u)$ ne soit pas le minimum des valeurs stockées dans le tas. De ce fait nous avons :

\begin{align} \exists t \in T_i \text{ tq } w(v,t) + Val(t) < w(v,u) + Val(u) \label{eq:dijk1} \end{align}

Mais cette inégalité signifierait qu'au noeud $v$ le joueur Min ferait mieux d'emprunter l'arc $(v,t)$ plutôt que l'arc $(v,u)$ ce qui contredit le fait que $\sigma_1^*$ est une stratégie optimale vu qu'elle possède une déviation profitable. Cela amène donc bien la contradiction attendue et prouve notre résultat.

Remarquons toutefois qu'il se pourrait qu'au lieu de~\eqref{eq:dijk1} on est : 

$$ \exists t \in T_i \text{ tq } w(v,t) + Val(t) = w(v,u) + Val(u) $$

Mais dans ce cas nous aurions que $\rho_i(v)= w(v,t) + Val(t) = w(v,u) + Val(u) = Val(v)$. 

\end{demonstration}

\begin{propriete}
	\label{prop:dijk2}
	Soit $i$ une certaine étape de l'algorithme et $v \in V\backslash \{ T_i \}$ tel que $v$ se trouve sur un chemin optimal et que le successeur de $v$ sur ce chemin, notons-le $u$, ai déjà été traité (\emph{i.e.,} $u \in T_i$) alors:
	$$ v \in V_{Max} \Rightarrow \rho_i(v) \leq Val(v).$$
\end{propriete}

\begin{demonstration} 
	$\text{}$\\
	Comme nous avons pris $v$ et $u$ sur un chemin optimal cela signifie qu'il existe $(\sigma_1^*, \sigma_2^*) \in \Sigma_{Min} \times \Sigma_{Max}$ des stratégies optimales telles que pour un certain $t \in V$ on ait : $\langle \sigma_1^*, \sigma_2^* \rangle_t = t\ldots vu\ldots$ .
Nous voulons montrer que si on connait $Val(u)$ alors on a : $Val(v) \geq \rho_i(v)$.

Supposons au contraire que $ rho_i(v) > Val(v)$. Nous avons alors : 
\begin{equation} \forall t \in T_i \text{ tq } (v,t)\in E_i \,\, w(v,t) + Val(t) > g(\langle \sigma_1^*, \sigma_2^*\rangle_v). \label{eq:dijk2}\end{equation}

De cette relation nous pouvons conclure. En effet, cela signifie que depuis le noeud $v$ le joueur Max possède une déviation profitable qui est d'emprunter un des arcs $(v,t)$ de~\eqref{eq:dijk2}. Ceci contredit le fait que $\sigma_2^*$ est une stratégie optimale.
	
\end{demonstration}

Maintenant que ces propriétés sont établies, reprenons la preuve d'exactitude de l'algorithme. Supposons que les invariants sont vérifiés jusqu'à l'étape $i$ et montrons qu'ils le sont toujours pour l'étape $i+1$.
Commençons par le montrer pour le premier invariant.

Soit $u \in T_i$ le noeud lu dans $Q$ (ligne~\ref{lalgo:dijk1} de l'algorithme \verb|DikjstraMinMax|). Comme il s'agit d'un minimum nous avons : $\forall v \in V\backslash \{ T_i \},\, \rho_i(u) \leq \rho_i(v)$. Plusieurs cas sont alors possibles. Pour plus de clarté, séparons ces cas en différents lemmes.

\begin{enumerate}
	\item \underline{$\rho_i(u) = +\infty$}: Dans ce cas pour tous les noeuds $v \in V\backslash \{ T_i \}$ (\emph{i.e.,} ceux restant dans $Q$) $\rho_i(v) = + \infty$ car $\rho_i(u) = \min _{v \in V\backslash \{ T_i \}} \{\rho_i(v)\}$. S'il s'agit d'un noeud du joueur Max cela signifie qu'il peut choisir un arc tel qu'après cet arc il est assuré que le joueur Min ne pourra pas atteindre un de ses objectifs. S'il s'agit d'un noeud du joueur Min cela signifie qu'à partir de ce noeud il ne pourra jamais atteindre un de ses états objectifs. La stratégie optimale consiste donc à choisir un arc au hasard dans ceux restant $E_i$.
	\item\underline{$\rho_i(u) < +\infty$ et $u \in Goal$}: Comme il s'agit d'un noeud objectif, on doit avoir que $Val(u) = 0$ ce qui est bien le cas car lors de l'initialisation de l'algorithme la valeur associée à chaque état objectif est 0 et elle ne peut pas être modifiée.
	\item\underline{$\rho_i(u) < +\infty$ et $u \in V_{Min}$}: Nous devons vérifier que nous pouvons calculer $Val(u)$ et donc que l'on peut rajouter $u$ aux éléments traités. Nous devons donc nous assurer que $Val(u) = \rho_i(u)$.
	Supposons au contraire que $Val(u) \neq \rho_i(u)$. Nous savons qu'il existe $(\sigma_1^*,\sigma_2^*) \in \Sigma_1 \times \Sigma_2 $ des stratégies optimales. Dès lors on a : $Val(u) = g(\langle \sigma_1^*, \sigma_2^* \rangle_u)$. Soit $\sigma_1$ la stratégie du joueur Min définie de la manière suivante : $$  \sigma(v) = \begin{cases}
											\displaystyle	\argmin_{v'\in T_i,(v,v')\in E_i} w(v,v') + Val(v') & \text{ si } v = u\\
												\sigma_1^*(v) &\text{ sinon} \end{cases}$$
Dès lors, nous avons : 

$$ Val(u) = \inf_{\tau_1 \in \Sigma_{Min}} g(\langle \tau_1 , \sigma_2^* \rangle_u) \leq g(\langle \sigma_1, \sigma_2^* \rangle_u) = \rho_i(u) $$

Mais comme nous avons supposé que $Val(u) \neq \rho_i(u)$, il en découle : 

\begin{equation} g(\langle \sigma_1^*, \sigma_2^* \rangle_u) < \rho_i(u).\label{eq:dijk3}\end{equation}

De plus, nous pouvons écrire: $\langle \sigma_1^*, \sigma_2^* \rangle_u = u \ldots xy \ldots$ où $x \in V\backslash \{ T_i \}$ et $y \in T_i$.

L'équation~\eqref{eq:dijk3} peut alors se réécrire: 

$$ g( u \leadsto x) + g(\langle \sigma_1^*, \sigma_2^* \rangle_x) < \rho_i(u).$$

Comme les poids sont positifs, l'inégalité suivante est également vérifiée:

\begin{equation}
	g(\langle \sigma_1^*, \sigma_2^* \rangle_x) < \rho_i(u). \label{eq:dijk4}
\end{equation}

Une étude de l'équation~\eqref{eq:dijk4} nous permet d'exhiber la contradiction souhaitée.

\begin{enumerate}
	\item \textbf{Si }$\mathbf{x \in V_{Min}}$: Par la propriété~\ref{prop:dijk1}, $\rho_i(x) = Val(x) = g(\langle \sigma_1^*, \sigma_2^* \rangle_x) < \rho_i(u)$. Or, on a choisi $u$ de telle manière que $\rho_i(u)$ soit minimal. 
	\item \textbf{Si }$\mathbf{x \in V_{Max}}$:	 Par la propriété~\ref{prop:dijk2}, $\rho_i(x) \leq Val(x) = g(\langle \sigma_1^*, \sigma_2^* \rangle_x) < \rho_i(u) $. Ce qui contredit également le choix de $u$.
	\item \textbf{Si }$\mathbf{x \neq u}$\textbf{ n'existe pas }: Par la propriété~\ref{prop:dijk1}, $\rho_i(u) = Val(u)$. Ce qu'on avait supposé faux.
\end{enumerate}

\item\underline{$\rho_i(u) < +\infty$ et $u \in V_{Max}$}: Remarquons que dans ce cas, pour qu'un sommet soit ajouté à l'ensemble des sommets traités, il faut qu'il ne reste plus qu'un arc \og non-bloqué \fg~ sortant du sommet $u$. Les autres arcs ont déjà été traités et n'ont pas été retenu pour la construction d'un chemin optimal. Notons cet arc $(u,u')$. Nous voulons montrer l'égalité suivante:

$$ \rho_i(u) = Val(u) .$$

Or, nous savons: 
$$ Val(u) = \sup _{\tau_2 \in \Sigma_2 } g( \langle \sigma^*_1, \tau_2 \rangle_u) = \max_{v \in V | (u,v) \in E} \{ w(u,v) + Val(v) \} .$$
Nous allons donc montrer:

\begin{equation*}
	\rho_i(u) = \max_{v \in V | (u,v) \in E} \{ w(u,v) + Val(v) \}.
\end{equation*}

Pour ce faire il nous suffit de montrer que pour tout sommet $v \in V$ l'inégalité suivante est respectée.

\begin{equation}
	\label{eq:dijk5}
	w(u,v) + Val(v) \leq \rho_i(u) = w(u,u') + Val(u') 
\end{equation}

Soit $v \in V$ tel que $v \neq u$ et $(u,v) \in E$, l'arc $(u,v)$ a été \og bloqué \fg~lors d'une certaine itération $j < i $ dans ce cas nous connaissons les trois relations suivantes:
\begin{equation} \label{eq:dijk6}
	  \rho_j(u) = w(u,v) + Val(v) 
	\end{equation}
\begin{equation*}  \rho_j(u) = \min_{v' \in T_j |(v,v') \in E_j} \{ w(u,v') + Val(v') \} \end{equation*}
\begin{equation*} \rho_j(u) \leq \rho_i(u) \end{equation*}
	
Nous pouvons donc déjà conclure que si $u' \in T_j$ alors l'inégalité~\eqref{eq:dijk5} est vérifiée.
Intéressons-nous maintenant au cas où $u' \in V \backslash T_j$. Nous savons qu'il existe $(\sigma_1^*, \sigma_2^*) \in \Sigma_1 \times \Sigma_2$ telles que $Val(u') = g( \langle \sigma_1^*, \sigma_2^* \rangle_{u'})$. 
Soit $x \in \langle \sigma_1^*, \sigma_2^* \rangle_{u'}$ un noeud sur le chemin optimal partant de $u'$ tel que $x \in V\backslash T_j$ et le successeur de $x$ sur ce chemin optimal appartient à $T_j$.
Alors:
$$ Val(u') = g( \langle \sigma_1^*, \sigma_2^* \rangle_{u'}) = w(u' \leadsto x) + g( \langle \sigma_1^*, \sigma_2^* \rangle_{x}) $$
Dès lors comme les poids sur les arcs sont positifs:

\begin{equation*}
	Val(u') \geq g( \langle \sigma_1^*, \sigma_2^* \rangle_{x})
\end{equation*}

Plusieurs cas sont alors à traiter:

\begin{enumerate}
	\item \textbf{Si }$\mathbf{x \in V_{Min}}$: Par la propriété~\ref{prop:dijk1}, nous savons:
	 \begin{equation}
		\label{eq:dijk8}\rho_j(x) = Val(x) = g(\langle \sigma_1^*, \sigma_2^* \rangle_x) \leq Val(u') .
	\end{equation}
	Nous pouvons dérouler la suite d'inégalités suivante qui nous permet de conclure : 
	\begin{align*}
		\rho_i(u) &= w(u,u') + Val(u')\\
		 		  &\geq Val(u') & \text{le poids des arcs est positif} \\
				  &\geq \rho_j(x) & \text{par}~\eqref{eq:dijk8} \\
				  &\geq \rho_j(u) & \text{à l'étape j on traite le noeud } u \text{ donc } \rho_j(u) \text{ minimal.}\\
				  &= w(u,v) + Val(v) & \text{par}~\eqref{eq:dijk6}						
	\end{align*}
	Ce qui prouve bien~\eqref{eq:dijk5}.
	\item \textbf{Si }$\mathbf{x \in V_{Max}}$:	 Par la propriété~\ref{prop:dijk2}, $\rho_j(x) \leq Val(x) = g(\langle \sigma_1^*, \sigma_2^* \rangle_x) \leq Val(u') $. Nous pouvons conclure par le même raisonnement que dans le cas précédant.
	\item \textbf{Si }$\mathbf{x \neq u'}$\textbf{ n'existe pas }: Par la propriété~\ref{prop:dijk1}, $\rho_j(u') = Val(u')$ et le raisonnement précédant est toujours valable.
\end{enumerate}
\end{enumerate}

Nous avons ainsi terminé la preuve concernant la premier invariant.\\

Pour le second invariant nous pouvons remarquer que pour tout $v \in V$ la valeur de $\rho_i(v)$ est susceptible d'être modifiée uniquement lorsque qu'un noeud est complètement traité et qu'une relaxation a lieu. Ce procédé est aussi bien effectuée pour un noeud du joueur Min que pour un noeud du joueur Max (ligne~\ref{lalgo:dijk2} de l'algorithme~\ref{algo:dijkMinMax}).\\

%PREUVE de la complexité
\noindent\textbf{Complexité de l'algorithme \textsc{DijkstraMinMax}}\\

Posons $n = |V|$ et $ m = |E|$.

Premièrement, nous rappelons les complexités dans le pire des cas des opérations sur les tas.

\begin{center}
	\begin{tabular}{|l|c|}
		\hline
		Opération & Complexité dans le pire cas \\
		\hline
		\hline
		\textsc{Lire-Min()} & $\mathcal{O}(1)$\\
		\hline
		\textsc{Extraire-Min()} & $\mathcal{O}(\log_2 n)$\\
		\hline
		\textsc{Insérer}(item) & $\mathcal{O}(\log_2 n)$\\
		\hline
		\textsc{Augmenter-Clef}($clef,valeur$) & $\mathcal{O}(\log_2 n)$\\
		\hline
		\textsc{Décrémenter-Clef}($clef,valeur$) & $\mathcal{O}(\log_2 n)$\\
		\hline
		
	\end{tabular}
\end{center}

Deuxièmement, avant de nous intéresser à la complexité de l'algorithme principal~\ref{algo:dijkMinMax} nous établissons la complexité des algorithmes secondaires.

\begin{enumerate}
	\item \textsc{Initialiser-S}($G,Goal)$ : Pour chaque noeud on instancie un tas en $\mathcal{O}(1)$ et on initialise la racine de celui-ci en $\mathcal{O}(1)$. Comme il y a $n$ noeuds, l'algorithme est en $\mathcal{O}(n)$.
	
	\item \textsc{Initialiser-Q}($G,Goal)$ : On  commence par instancier un tas $Q$ en $\mathcal{O}(1)$. Ensuite, on rajoute une valeur pour chacun dans noeud dans $Q$. Rappelons que la complexité de de l'insertion dans un tas est $\mathcal{O}$(hauteur du tas), dans ce cas, comme les valeurs sont rajoutées une à une, la complexité est en $\mathcal{O}(n)$.
	
	\item \textsc{Relaxer}$(p, s, w)$ : Les instructions~\refrangeconj{lalgo:relaxer1}{lalgo:relaxer4} sont effectuées en $\mathcal{O}(1)$ tandis que celles~\refrangeconj{lalgo:relaxer5}{lalgo:relaxer10} sont en $\mathcal{O}(\log_2 n)$ à cause de l'instruction \textsc{Décrémenter-Clef}. Enfin, les instructions~\refrangeconj{lalgo:relaxer11}{lalgo:relaxer12} ont une complexité en $\mathcal{O}(\log_2 n)$. Dès lors, la complexité de cet algorithme secondaire est en $\mathcal{O}(\log_2 n)$.
	
	 \item \textsc {Bloquer-Max}$(s)$: Les instructions~\ref{lalgo:bloc1} et~\ref{lalgo:bloc2} sont en $\mathcal{O}(\log_2 n)$ tandis que les autres sont en $\mathcal{O}(1)$. Dès lors la complexité de cet algorithme est en $\mathcal{O}(\log_2 n)$.
	
	
\end{enumerate}

Nous pouvons maintenant clôturer l'analyse de l'algorithme \textsc{DijkstraMinMax} en démontrant que sa complexité est en $\mathcal{O}((m+n)\log_2 n)$. Pour se faire une analyse minutieuse des instructions~\refrangeconj{lalgo:dijk4}{lalgo:dijk23} est nécessaire. En effet, plutôt que de calculer la complexité du corps de la boucle \og tant que\fg~et ensuite le nombre de fois où l'on rentre dans cette boucle, nous préférons une analyse globale. Nous nous intéressons donc, pour chaque instruction, au nombre de fois où celle-ci est exécutée dans le pire cas et ce sur l'entièreté de l'exécution de l'algorithme.

\begin{itemize}
	\item[$\bullet$] Pour les lignes~\ref{lalgo:dijk1} et~\ref{lalgo:dijk6} sont exécutées dans le pire cas $n$ fois. Donc, la complexité globale de ces deux lignes est en $\mathcal{O}(n)$.
	\item[$\bullet$] Pour la condition \og si \fg~\refrangeconj{lalgo:dijk7}{lalgo:dijk11}, la complexité globale est également en   	 $\mathcal{O}(n \log_2 n)$.
	
	\item[$\bullet$] Pour la condition \og sinon \fg~\refrangeconj{lalgo:dijk12}{lalgo:dijk22}, il est important de remarquer qu'un arc ne peut être relaxé qu'une seule fois. De ce fait, la complexité globale de l'instruction \textsc{Relaxer}$(p,s,w)$~\ref{lalgo:dijk2} est en $\mathcal{O}(m \log_2 n)$. Nous pouvons ainsi affirmer que le bloc d'instructions~\refrangeconj{lalgo:dijk13}{lalgo:dijk18} est en $\mathcal{O}((m+n) \log_2 n)$ tandis que celui~\refrangeconj{lalgo:dijk19}{lalgo:dijk21} est en $\mathcal{O}((m+n) \log_2 n)$. Ce qui nous fait une complexité globale pour toute la condition en $\mathcal{O}((m+n) \log_2 n)$
	
\end{itemize}

Comme les initialisations des tas sont en $\mathcal{O}(n)$, nous pouvons enfin conclure que l'algorithme \textsc{DijkstraMinMax} a une complexité en $\mathcal{O}((m+n) \log_2 n)$.
	


 