%!TEX root=main.tex

\section{Recherche d'équilibres de Nash pertinents}

Le background sur les jeux d'atteignabilité ayant été clairement expliqué, nous nous intéressons à la recherche - de manière algorithmique - d'équilibres de Nash \og pertinents \fg. Dans un premier temps, nous définissons clairement l'objectif que nous désirons atteindre ainsi que ce signifie pour nous des équilibres de Nash pertinents. Ensuite, nous établissons quelques remarques et propriétés qui nous sont utiles afin de mener à bien notre raisonnement. Enfin, nous expliquons de quelle manière nous désirons mettre en oeuvre des procédés permettant de résoudre cette problématique.

\subsection{Définition du problème et des équilibres pertinents}

Tout d'abord, soit $\mathcal{G} = ( \{ 1,2 \}, V, (V_{1}, V_{2}),E, (Cost _{1},Cost _{2}))$, considérons le jeu $(\mathcal{G},v_{1})$ où:\begin{enumerate}
\item[$\bullet$] Pour tout  $\rho = \rho _{0} \rho _{1} \rho _{2} \ldots $ où $\rho \in Plays$ :\\$Cost_{i}(\rho) = $ $\begin{cases} 
								\min \{ i | \rho _{i} \in Goal_{i} \} & \text{si } \exists i \text{ tq } \rho _{i} \in Goal_{i} \\
								+\infty & \text{ sinon}
								\end{cases}$,
\item[$\bullet$] $Goal_{1} = \{ v_{3} \}$ et $Goal_{2} = \{ v_{0} \}$,
\item[$\bullet$]  $V_{1}$ (resp. $V_{2}$) est représenté par les noeuds ronds (resp. carrés) du graphe de la figure~\ref{ex:patologique}.

\end{enumerate}


\begin{figure}[ht!]
	\centering

	\begin{tikzpicture}
		
		\node[nRG] (v3) at (2,-2){$v_{3}$};
		\node[nC] (v2) at (2,0){$v_{2}$};
		\node[nR] (v1) at (0,0){$v_{1}$};
		\node[nRD] (v0) at (0,-2){$v_{0}$};
	
		\draw[->,>=latex] (v0) to [bend right] (v1);
		\draw[->,>=latex] (v1) to [bend right] (v0);
		
		\draw[->,>=latex] (v1) to [bend right] (v2);
		\draw[->,>=latex] (v2) to [bend right] (v1);
		
		\draw[->,>=latex] (v3) to [bend right] (v2);
		\draw[->,>=latex] (v2) to [bend right] (v3);
		
		
	\end{tikzpicture}
	
	\caption{Jeu d'atteignabilité avec coût}
	\label{ex:patologique}
	

\end{figure}

Soit $\sigma _{1}(v) =$ $\begin{cases}
						v_{2} & \text{si } v = v_{1} \\
						v_{1 } & \text{si } v = v_{0} \\
						v_{2} & \text{si } v = v_{3} 
						\end{cases}$
						
						
						
\noindent et soit $\sigma _{2}(v) = v_{1}$ alors $(\sigma _{1},\sigma _{2})$ est un équilibre de Nash du jeu $(\mathcal{G},v_{1})$ dont l'outcome est $(v_{1}v_{2})^{\omega}$. Nous remarquons qu'avec cet équilibre de Nash aucun des deux joueurs n'atteint son objectif. Nous pouvons également observer que si les deux joueurs coopéraient, ils pourraient tous deux minimiser leur coût. En effet, si les deux joueurs suivaient un profil de stratégie ayant comme outcome $\rho = v_{1}v_{0}v_{1}(v_{2}v_{3})^{\omega} $ nous aurions $Cost_{1}(\rho) = 4$ et $Cost_{2}(\rho) = 1$.

La question que nous nous posons alors est la suivante : \og Etant donné un jeu d'atteignabilité à objectifs quantitatif et multijoueur, nous souhaitons trouver de manière rapide un équilibre de Nash pertinent \fg. Nous avons donc dû nous interroger au sens à donner au concept d'équilibre de Nash pertinent.

Au vu de l'exemple ci-dessus, nous avons mis en lumière le fait que pour certains équilibres de Nash, aucun joueur ne voyait son objectif atteint. Dès lors nous pouvons établir qu'un équilibre de Nash pertinent vérifie:

\begin{itemize}
	\item[$\bullet$] Si on est dans un type de jeu tel qu'il existe (au moins) un équilibre de Nash tel que tous les joueurs voient leur objectif atteint alors on souhaite que si $\rho$ est l'outcome de l'équilibre de Nash trouvé on ait que:
	$ \sum_{i \in \Pi} Cost_i(\rho)$ soit \textbf{minimale}.
	\item[$\bullet$]S'il n'est pas certain qu'il existe un équilibre de Nash du type de celui décrit ci-dessus alors on désire \textbf{maximiser} le nombre de joueurs qui atteignent leur objectif, notons cet ensemble de joueurs $A$. De plus, on souhaite \textbf{minimiser} $\sum_{i \in A} Cost_i(\rho)$.
\end{itemize}

\subsection{Caractérisation de l'outcome d'un équilibre de Nash}

Une des premières questions que nous nous sommes alors posée est la suivante:
\begin{qst}
	\label{qst:1}
	
	Soit $G = (V,E)$ un graphe orienté fortement connexe \footnote{En théorie des graphes, un graphe $G = (V,E)$ est dit fortement connexe si pour tout $u$ et $v$ dans $V$, il existe un chemin de $u$ à $v$} qui représente l'arène d'un jeu d'atteignabilité multijoueur avec coût : $(\mathcal{G},v_{0})$ (pour un certain $v_{0} \in V$).
Existe-t'il un équilibre de Nash tel que chaque joueur atteigne son objectif?

\end{qst}

Nous n'avons pas encore de réponse claire à cette question. Toutefois, pour un jeu à $n$ joueurs nous avons une bonne intuition quant à la manière de passer d'un équilibre de Nash où $n-1$ joueurs atteignent leur objectif à un équilibre de Nash où $n$ joueurs atteignent leur objectif.\\

Nous remarquons que si nous répondons positivement à cette question alors nous rentrerons dans les conditions explicitées dans le premier point de la section précédente.

\todo{Que faire?}


Maintenant, nous nous demandons s'il existe un processus algorithmique qui permet de déterminer si un outcome particulier correspond à l'outcome d'un équilibre de Nash. Dans le cas échéant, nous désirons expliciter ce procédé. Dans la suite de cette section nous répondons positivement à cette question. Nous énonçons d'abord une propriété (propriété~\ref{prop:rechEqpert1}) qui nous permet de déterminer une condition nécessarire et suffisante pour qu'un outcome soit l'outcome d'un certain équilibre de Nash. Toutefois, pour pouvoir effectuer une procédure algorithmique sur les outcomes, il faut que nous trouvions un moyen de représenter ceux-ci car nous travaillons avec des mots infinis. Nous nous convainquons donc par la suite que nous pouvons nous restreindre à l'étude d'équilibres de Nash dont l'outcome est de la forme $\alpha \beta^{\omega}$ où $\alpha$ et $\beta$ sont des mots finis. 

Avant de stipuler notre propriété, nous devons aborder quelques notions qui nous sont nécessaires.


\begin{defi}
	\label{defi:coalGame}
 Soient $\mathcal{A} = (\Pi, V, (V_{i})_{i\in\Pi}, E)$ une arène,\\
et $\mathcal{G} = (\mathcal{A}, (\varphi _{i})_{i\in\Pi}, (Goal_{i})_{i\in\Pi})$ un jeu d'atteignabilité à $|\Pi| \geq 2$ à objectif quantitatif.
Pour tout joueur $i \in \Pi$, nous pouvons y associer un jeu à somme nulle de type \og reachability-price game \fg~noté $\mathcal{G}_{i}$.
On définit ce jeu de la manière suivante : 
$ \displaystyle \mathcal{G}_{i}= (\mathcal{A}_{i}, g , Goal) \text{ où }$:
\begin{itemize}
	\item[$\bullet$] $\mathcal{A}_{i} = (\{i,-i \}, V, (V_{i},V\backslash V_i),E)$
	\item[$\bullet$] $g = \varphi_i$ 
	\item[$\bullet$] $Goal = Goal_i$
\end{itemize}

\noindent De plus, pour tout $v\in V$, $Val_i(v)$ est la valeur du jeu $\mathcal{G}_i$ pour tout noeud $v\in V$. 
\end{defi} 

En d'autres mots, $G_i$ correspond au jeu où le joueur $i$ (joueur Min) joue contre la coalition $\Pi\backslash\{ i \}$ (joueur Max). Cela signifie que le joueur $i$ tente d'atteindre son objectif le plus rapidement possible tandis que tous les autres joueurs veulent l'en empêcher (ou tout du moins maximiser son gain). Nous avons vu précédemment qu'un tel jeu est déterminé et que les deux joueurs possèdent une stratégie optimale ($\sigma^*_i$ et $\sigma^*_{-i}$) telles que:
$$ \inf_{\sigma _{i\in \Sigma _{Min}}} \varphi_i(\langle \sigma_i,\sigma^*_{-i}\rangle_v)= Val_i(v) = \sup _{\sigma_{-i}\in \Sigma_{Max}} \varphi_i(\langle \sigma^*_i, \sigma_{-i}\rangle_v).$$ De plus, de la stratégie optimale $\sigma^*_{-i}$ nous pouvons dériver une stratégie pour tout joueur $j \neq i$ que nous notons $\sigma_{j,i}$.\\

Nous sommes maintenant apte à énoncer notre propriété. La preuve de celle-ci a été effectuée par nos soins, mais nous faisons remarquer qu'une preuve similaire dans le cas des jeux concurrents à informations parfaites a déjà été effectuée par Haddad~\cite{characNashEq}. Pour ce faire, nous avons besoin d'introduire quelques notions préliminaires.

\begin{propriete}
	\label{prop:rechEqpert1}
	Soit $|\Pi| = n \geq 2$,
	soient $\mathcal{A} = (\Pi, V, (V_{i})_{i\in\Pi}, E)$ une arène et $\mathcal{G} = (\mathcal{A}, (\varphi _{i})_{i\in\Pi}, (Goal_{i})_{i\in\Pi})$ un jeu d'atteignabilité à $n$ joueurs à objectif quantitatif, soit $(\mathcal{G}, v_{0})$ le jeu initialisé pour un certain $v_{0} \in V $ et soit $\rho = v_{0}v_{1}... \in Plays$. 
	
	Posons $(x_{i})_{i\in\Pi} = (\varphi _{i}(\rho))_{i\in\Pi}$ le profil de paiement associé à la partie $\rho$. Nous définissons pour $v_{k} \in \rho$ ($k \in \mathbb{N}$)  $\varepsilon _{k} := \sum _{n= 0} ^{k-1} w(v_{n},v_{n+1})$ où $w$ est la fonction de poids associée à $G = (V,E)$.
	
	\begin{center}Il existe $ (\sigma _{i})_{i\in\Pi} \in \prod_{i\in\Pi} \Sigma _{i}$ un équilibre de Nash dans $(\mathcal{G},v_{0})$ tq $\langle (\sigma _{i})_{i \in \Pi}\rangle_{v_0} = \rho$\\ $\text{}$\\ si et seulement si\\$\text{}$\\  $ \forall k \in \mathbb{N}, \forall j \in \Pi$, $Val_{j}(v_{k}) + \varepsilon _{k} \geq x_j \text{  si } v_{k} \in V_{j}$.\end{center}
	
\end{propriete}

\setcounter{equation}{0}

\begin{demonstration}
	Nous allons montrer les deux implications:\\
	\begin{itemize}
		\item[$(\Downarrow)$] Supposons au contraire qu'il existe $k\in \mathbb{N}$ et $j\in\Pi$ tels que $Val_j(v_k) + \varepsilon_k < x_j$,
		\begin{equation}
			\label{eq:questEq1}
			i.e., Val_j(v_k) < x_j + \varepsilon_k = \varphi_j(\langle (\sigma_i)_{i \in \Pi}\rangle_{v_k})
		\end{equation}
		où $\varphi_j(\langle (\sigma_i)_{i \in \Pi}\rangle_{v_k})$ est le coût de la partie pour le joueur $j$ si elle avait commencé en $v_k$.
		De plus, on a : 
		\begin{align}
			\label{eq:questEq2}
			Val_j(v_k) &= \sup_{\tau_{-j}\in \Sigma_{Max}} g(\langle \sigma^*_j,\tau_{-j} \rangle_{v_k}) \notag\\
			           &\geq g (\langle \sigma^*_j,\sigma_{-j} \rangle_{v_k}) = \varphi_j(\langle \sigma^*_j,\sigma_{-j} \rangle_{v_k})
		\end{align}
		où $\sigma^*_j$ est la stratégie optimale du joueur $j$ associée à $\mathcal{G}_j$ et $\sigma_{-j}$ dans l'expression $g (\langle \sigma^*_j,\sigma_{-j} \rangle_{v_k})$ est un abus de notation désignant la stratégie où la coalition $\Pi\backslash\{ j \}$ suit chacune des stratégies $\sigma_i$ pour tout $i \neq j$.\\
		
		Dès lors, \eqref{eq:questEq1} et \eqref{eq:questEq2} nous donnent:
		\begin{equation}
			\label{eq:questEq3}
			\varphi_j(\langle \sigma^*_j,\sigma_{-j} \rangle_{v_k}) < \varphi_j(\langle(\sigma_i)_{i\in \Pi}\rangle_{v_k})
		\end{equation}
		
		La relation~\eqref{eq:questEq3} signifie qu'à partir du noeud $v_k$ le joueur $j$ ferait mieux de suivre la stratégie $\sigma^*_j$. Il s'agit donc d'une déviation profitable pour le joueur $j$ par rapport au profil de stratégies $(\sigma_i)_{i\in \Pi}$. Cela implique que $(\sigma_i)_{i\in\Pi}$ n'est pas un équilibre de Nash. Nous avons donc la contradiction attendue.\\
		
		\item[$(\Uparrow)$] Soit $(\tau_i)_{i\in \Pi}$ un profil de stratégies qui permet d'obtenir l'outcome $\rho$ de paiement $(x_i)_{i\in\Pi}$.
		A partir de $(\tau_i)_{i\in \Pi}$ nous désirons construire un équilibre de Nash ayant le même outcome (et donc le même profil de coût).
		L'idée est la suivante: dans un premier temps tous les joueurs suivent leur stratégie conformément au profil $(\tau_i)_{i \in \Pi}$. Si un des joueurs, notons le $i$,  dévie de sa stratégie alors les autres joueurs se réunissent en une coalition $\Pi\backslash \{ i \}$ et jouent en suivant leur stratégie de punition dans $\mathcal{G}_i$ (\emph{i.e.,} pour tout j $\neq$ i, le joueur $j$ suit la stratégie $\sigma^*_{j,i}$).\\
		
	Comme dans le papier \og Multiplayer Cost Games With Simple Nash Equilibria \fg~\cite{DBLP:conf/lfcs/BrihayePS13}, nous définissons une fonction de punition: $P : Hist \rightarrow \Pi\cup \{ \perp \}$ qui permet de définir quel est le premier joueur à avoir dévié du profil de stratégies initial $(\tau_i)_{i\in\Pi}$. Cette fonction est telle que $P(h) = \perp$ si aucun joueur n'a dévié le long de l'histoire $h$ et $P(h) = i$ pour un certain $i \in \Pi$ si le joueur $i$ a dévié le long de l'histoire $h$. Nous pouvons donc définir la fonction $P$ par récurrence sur la longueur des histoires : pour $v_0$, le noeud initial, $P(v_0) = \perp$  et pour $h \in Hist$ et $v\in V$ on a :
	
	$$
	P(hv) = \begin{cases}
			\perp & \text{ si } P(h) = \perp \text{ et } hv \text{ est un préfixe de } \rho \\
			i & \text{ si } P(h) = \perp ,\, hv \text{ n'est pas un préfixe de }\rho \text{ et } Last(h)\in V_i\\
			P(h) & \text{ sinon (\emph{i.e.,}}\, P(h)\neq \perp) \end{cases}
	$$\\
	
	Nous pouvons maintenant définir notre équilibre de Nash potentiel dans $\mathcal{G}$. Pour tout $i\in \Pi$ et tout $h\in Hist$ tels que $Last(h)\in V_i$:
	$$\sigma_i(h)= \begin{cases}
					\tau_i(h) & \text{ si }P(h)= \perp \text{ ou }i \\
					\sigma^*_{i,P(h)}(h) & \text{ sinon }\end{cases}$$\\
					
	Nous devons maintenant montrer que le profil de stratégies $(\sigma_i)_{i\in\Pi}$ ainsi défini est un équilibre de Nash d'outcome $\rho$.\\
	Il est clair que $\langle (\sigma_i)_{i\in\Pi} \rangle_{v_0} = \rho$.\\
	Montrons maintenant qu'il s'agit bien d'un équilibre de Nash.\\
	\noindent Supposons au contraire que ce ne soit pas le cas. Cela signifie qu'il existe une déviation profitable ( $\tilde{\sigma}_j$) pour un certain joueur $j \in\Pi$.\\ 
		\noindent Soit $\tilde{\rho} = \langle \tilde{\sigma}_j , (\sigma_i)_{i \in \Pi \backslash \{j \}} \rangle_{v_0}$ l'outcome tel que le joueur $j$ joue sa déviation profitable et où les autres joueurs jouent conformément à leur ancienne stratégie.
		Puisque $\tilde{\sigma}_j$ est une déviation profitable nous avons: 
		\begin{equation}
			\label{eq:questEq4}
			\varphi_j(\tilde{\rho}) < \varphi_j(\rho)
		\end{equation}
		
		De plus, comme $\rho$ et $\tilde{\rho}$ commencent tous les deux à partir du noeud $v_0$, ils possèdent un préfixe commun. En d'autres termes, il existe une histoire $hv \in Hist$ telle que: 
		\begin{equation*}
			\rho = h. \langle (\sigma_i)_{i\in\Pi} \rangle_v \text{ et } \tilde{\rho} =  h.\langle \tilde{\sigma_j}, (\sigma)_{i\in\Pi\backslash \{ j \}} \rangle_v
		\end{equation*}
		 S'il en existe plusieurs nous en choisissons une de longueur maximale.
		Au vu de la définition de $\sigma_i$, nous pouvons réécrire:
		
		\begin{equation*}
			\rho = h. \langle (\tau_i)_{i\in\Pi} \rangle_v \text{ et } \tilde{\rho} = h.\langle \tilde{\sigma_j}, (\sigma^*_{i,j})_{i\in\Pi \backslash\{ j \} }\rangle_v
		\end{equation*}
		En effet, le joueur $j$ dévie en $v$, donc à partir de $v$ tout joueur $i \neq j$ joue sa stratégie de punition. De plus, nous avons les relations suivantes : 
		\begin{align}
			Val_j(v) &= \inf_{\mu_j\in\Sigma_{Min}}\varphi_j(\langle \mu_j, \sigma^*_{-j}\rangle_v)\notag\\
					 &\leq \varphi_j(\langle \tilde{\sigma}_j, \sigma^*_{-j}\rangle_v)\notag\\
					& = \varphi_j(\langle \tilde{\sigma}_j, (\sigma^*_{i,j})_{i \in \Pi \backslash \{ j \}}\rangle_v). \label{eq:questEq5}
		\end{align}
		
	Supposons $h = v_0 \ldots v_k$ pour un certain $k \in \mathbb{N}$. Alors,
	\begin{equation}
		\label{eq:questEq6}
		\varphi_j(\tilde{\rho}) = \varepsilon_k + \varphi(\langle \tilde{\sigma}_j , (\sigma^*_{i,j})_{i\in\Pi\backslash\{ j \}}\rangle_v)
	\end{equation}
	Dès lors, \eqref{eq:questEq5} et~\eqref{eq:questEq6} nous donnent:
	\begin{equation}
		\label{eq:questEq7}
		Val_j(v) \leq \varphi_j(\tilde{\rho}) - \varepsilon_k
	\end{equation}
	
	Donc par~\eqref{eq:questEq4} et~\eqref{eq:questEq7}  nous avons:
	$$ Val_j(v) \leq \varphi_j(\tilde{\rho})- \varepsilon_k < \varphi_j(\rho)-\varepsilon_k = x_j-\varepsilon_k$$
	Ce qui contredit l'hypothèse et conclut notre preuve.
	\end{itemize}
\end{demonstration}

Dans~\cite{juliePhd}, une procédure est explicitée afin de construire à partir d'un équilibre de Nash un équilibre de Nash du même \emph{type} telles que toutes les stratégies sont à mémoire finie. Le type d'un profil de stratégies est l'ensemble des joueurs qui ont visité leur objectif en suivant cet équilibre. Si le profil de stratégies est $(\sigma_i)_{i \in Pi}$ alors on note le type de ce profil $\type((\sigma_i)_{i\in \Pi})$. Le théorème suivant est donc énoncé:

\begin{thm}
	Etant donné un équilibre de Nash dans un jeu multijoueur initialisé à objectif quantitatif, il existe un équilibre de Nash du même type
\end{thm}

Ce procédé consiste en deux étapes. Etant donné un équilibre de Nash, on commence par construire un second équilibre de Nash du même type duquel on a supprimé les cycles inutiles. Un cycle inutile est un cycle tel que lors de son parcourt aucun joueur qui n'avait pas encore visité son objectif n'atteint celui-ci. Ensuite, on construit un équilibre de Nash $(\sigma_i)_{i\in \Pi}$, toujours avec le même type, tel qu'à partir de l'outcome $\langle (\sigma_i)_{i\in \Pi}\rangle_{v_0}$ on puisse identifier un préfixe $\alpha\beta$ tel que l'on puisse répéter infiniment $\beta$.
Remarquons toutefois que dans le cadre de ces preuves, le fonction de poids $\phi: E \rightarrow \mathbb{R}$ est la fonction telle que pour tout $e \in E$, $\phi(e) = 1$. Les preuves s'adaptent toutefois si la fonction de poids est de la forme $\phi : E \rightarrow \mathbb{R}^{+}$.\\
\todo{Justifications? $\mathbb{R}^{+}$ ou $\mathbb{N}_{0}$ ???}\\

Nous pouvons donc conclure qu'il est moralement correct de se restreindre à le recherche d'équilibres de cette forme. En effet, vu qu'ils possèdent le même type cela n'influence pas notre désire de maximiser le nombre de joueurs d'atteindre leur objectif. De plus, puisque les poids sur les arcs sont tous des des poids positifs, la suppression des cycles lors de la première étape de la procédure ne fait que potentiellement diminuer le coût des joueurs pour cet équilibre. Cette modification est à notre avantage, en effet, cela diminue la somme des coûts des joueurs. Ce qui est exactement la valeur que nous désirons minimiser pour trouver un équilibre pertinent.\\

Nous avons désormais à notre disposition:
\begin{itemize}
	\item[$\bullet$] Une manière de tester si un outcome correspond à l'outcome d'un équilbre de Nash.
	\item[$\bullet$] Un résultat permettant d'affirmer que nous pouvons nous contenter d'examiner les équilibres de Nash de la forme $\alpha \beta^{\omega}$ où $\alpha$ et $\beta$ sont des éléments de $V^{+}$. De là, nous pouvons appliquer le point précédant sur $\alpha\beta$ et comme ce mot est un mot fini, un algorithme peut effectuer cette tâche.
	\item[$\bullet$] Un algorithme (\verb|DijkstraMinMax|) qui permet des récupérer les valeurs des joueurs où les joueurs jouent en coalition. Ces valeurs permettent de vérifier si la propriété du point précédent est respectée.
\end{itemize}
Il nous reste donc à déterminer un algorithme qui nous permet de trouver rapidement un équilibre de Nash pertinent. Pour ce faire, nous avons décidé d'explorer la piste des \emph{heuristiques} et particulièrement celle de la \emph{recherche locale} via la méthode de \emph{hill-climbing}. La section suivante rappelle ces notions et explicite comment nous désirons les appliquer à notre problématique.


\include{rechercheLocale}
\include{conclusionRechLoc}





